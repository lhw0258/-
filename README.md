# 爪爪识别



## 1.课题方向

​		基于OpenCV的手势识别，用python3实现



## 2.背景

​		在日常生活中，难免会和使用手语的人交流。这时大多数普通人没有使用过手语，不会手语。那么为了解决这个问题，我们研究出一种想法，将手势/手语用机器识别，识别过后转换成文字输出/语音输出。这样方便了手语使用者，也让大众可以顺畅的与手语使用者的交流。

选题背景与研究现状
国外：
\>英国Essex大学通过识别人脸，比较当前人脸形状和模板人脸形状来估计人脸方向，从而控制智能轮椅。
\>美国CMU机器人实验室实现了一种能够按人体手势及手臂动作做出简单动作的清扫机器人。
\>2007年Amin Bhuiyan等人研究的通过人脸及人脸角度控制机器人AIBO的动作或者姿势。
\>2010年印度学者已经实现应用手势远程控制机器人的运动状态为前进、后退、左转、右转和停止五个状态。
国内：
\>天津大学研究了汉语语音识别系统并用来控制机器人。
\>上海大学研究识别手势系统并将其成功地用于远程机器人控制系统。
\>天津大学实现了依据操作者的体态动作图像信息控制机器人的状态。
\>清华大学研究了一个手势识别系统，选择其中识别率较高的十种手势类别作为人机互动信号应用于电脑游戏中代替手柄。



## 3.大致功能

​		识别模式：

​			将简单的手势/手语识别，并将其转换为文字。

​		读取模式：

​			将简单的手势/手语识别，并将其转换为命令。



## 4.工作计划

主体程序		

​		获取手部图像

​		处理手部图像

​			图像预处理

​			特征识别

​		算法计算

​		输出结果

控制器

​		登录

​		模式切换

​		退出

​		

## 5.计划分工

1.  逻辑算法——李航，刘弘炜

2.  代码实现——熊祎，李航

3.  程序调试——刘弘炜，孙小燕

4.  BUG修复——兰馨，熊祎

5.  PPT制作 —— 兰馨，孙小燕


6.  整体测试打包——熊祎，谢太俊
7.  答辩演讲——谢太俊，孙小燕，熊祎

## 6.时间节点

9月30日——思考想法

10月8日——找到方向

10月15日——获取各方面的资料和数据

11月1日——代码逻辑初步实现

11月3日——测试失败

11月4日——改变算法

11月5日——再次测试，失败

11月7日——大体结构确定，重写算法

11月13日——主体程序代码测试成功

11月20日——完成了部分BUG和算法的优化

11月27日——完成控制器的代码逻辑

12月1日——PPT制作

12月8日——PPT制作完成

12月9日——控制器和主体程序合并测试成功

12月13日——撰写文档，打包



## 7.下载使用

环境需求：python3

用命令`pip install -r requirements.txt`

下载完成后

使用命令`python main.py`

运行

默认登陆密码000000
